{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use this file, follow installation instructions at https://github.com/UKPLab/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # # XLNet has no size limit (we are still limited by RAM)\n",
    "# # # XLNet returns embedding for each token, unpooled\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "# # model = AutoModel.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "# chunk = next(chunks(text, chunk_size=100))\n",
    "# inputs = tokenizer(chunk, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "\n",
    "# outputs.pooler_output[0]\n",
    "# # outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext lab_black\n",
    "except ModuleNotFoundError:\n",
    "    print(\"nb_black not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickledb\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"Lightbulb-top-1000-results\"\n",
    "# source = \"SomebodyMakeThis-top-1000-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{source}.json\") as file:\n",
    "    data = json.load(file)\n",
    "data = data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_text = {post[\"url\"]: post[\"title\"] + \" \" + post[\"selftext\"] for post in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(text, chunk_size=100, stride=0.8):\n",
    "    words = text.split(\" \")\n",
    "    displacement = int(chunk_size * stride)\n",
    "\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        chunk = words[start : start + chunk_size]\n",
    "        yield \" \".join(chunk)\n",
    "        start += displacement\n",
    "\n",
    "\n",
    "def chunk_and_embed(text, model):\n",
    "    # TODO now each chunk has a constant number of words, but maybe it should have a constant number of tokens\n",
    "    embeddings = []\n",
    "    for chunk in chunks(text, chunk_size=80):\n",
    "        embedding = model.encode(chunk)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    final_embedding = np.average(embeddings, axis=0)\n",
    "    return final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_embedding = dict()\n",
    "for url in tqdm(url_to_text.keys(), ncols=80, smoothing=0.05):\n",
    "    text = url_to_text[url]\n",
    "    embedding = chunk_and_embed(text, model)\n",
    "    url_to_embedding[url] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{source}-embeddings.pickle\", \"wb\") as file:\n",
    "    pickle.dump(url_to_embedding, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-transformers",
   "language": "python",
   "name": "simple-transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
